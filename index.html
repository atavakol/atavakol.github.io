<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" >

<head>

<style type="text/css">
* {
  font-family: sans-serif;
}
h1
{
margin-top: 0;
margin-bottom: 0;
}
h3
{
margin-top: 0;
margin-bottom: 0;
}
body
{
color: #000000;
background: #FDFEFE;
}
a:link { 
color: #264889;
text-decoration: none;
}
a:visited { 
color: #264889;
}
a:hover { 
color: #117A65;
text-decoration: none;
}
a:active { 
color: #74AFAD;
}
sup {
    vertical-align: super;
    font-size: smaller;
}
.bottom-three {
    margin-bottom: 1.5mm;
}
</style>
<link rel="icon" type="image/png" href="images/imp-icon.png">

<title>Arash Tavakoli</title>

</head>

<body>

<center>
<table>
    <tr>
        <td style="width: 740px" valign=top align=left>

            <table cellpadding=10px>
                <tr>
                    <td valign=top align="right" width=30%>
                        <img src="images/aureche.png" alt="Arash Tavakoli" height="250" border=1/>

                    </td>
                    <td align=left valign=top width=70%>
                        <a id="top"></a>
                        <h1>Arash Tavakoli</h1><br>
                        PhD Candidate in Computer Science <br>
                        (Deep Reinforcement Learning) <br><br>
                        Imperial College London<br><br>
                        <TT>a.tavakoli</TT> [at] <TT>imperial.ac.uk</TT><br><br>
                        <a href="https://twitter.com/arshtvk"><img src="images/twitter-circ.png" alt="twitter" height="60"/></a>
                        <a href="https://github.com/atavakol"><img src="images/github-circ.png" alt="github" height="60"/></a>
                        <a href="https://www.linkedin.com/in/arashtavakoli/"><img src="images/linkedin-circ.png" alt="linkedin" height="60"/></a>
                        <a href="https://scholar.google.co.uk/citations?user=Jwq-Qx0AAAAJ&hl=en&oi=ao"><img src="images/google-scholar-circ.png" alt="google scholar" height="60"/></a>
                    </td>
                </tr>
            </table>

<!--p align=justify>
My research focuses on deep reinforcement learning problems, such as improving exploration in high-dimensional state-action spaces. Furthermore, given my background in multi-agent control systems, I am intrigued by the potential applications of deep reinforcement learning in such settings.  
</p-->

<body>
    <div class="row">
        <div class="col-md-4 col-md-offset-4">
            <h2>News</h2>
            <ul>
                <li class="bottom-three">
                    Dec 2018: Paper accepted at the <a href="https://sites.google.com/view/deep-rl-workshop-nips-2018/home">Deep Reinforcement Learning Workshop</a>, <a href="https://neurips.cc/">Conference on Neural Information Processing Systems (NeurIPS)</a> 2018 in Montréal, Québec.<br>
                </li>

                <li class="bottom-three">
                    Sep 2018: <a href="https://unity3d.com/machine-learning">Unity ML-Agents</a> now has support for our action branching architectures, and comes equipped with an action branching variant of PPO (see <a href="https://blogs.unity3d.com/2018/09/11/ml-agents-toolkit-v0-5-new-resources-for-ai-researchers-available-now/">official blog</a>).  
                </li>

                <li class="bottom-three">
                    Aug 2018 – Nov 2018: Started as a Research Intern at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-montreal/">Microsoft Research</a> in Montréal, Québec.  
                </li>

                <li class="bottom-three">
                    Jul 2018: Attended the <a href="https://dlrlsummerschool.ca/">Deep Learning and Reinforcement Learning Summer Schools</a>,
                    organized by <a href="https://www.cifar.ca/">CIFAR</a>, <a href="https://vectorinstitute.ai/">Vector Institute</a>, <a href="https://www.amii.ca/">Amii</a>, and <a href="https://mila.quebec/en/">Mila</a>, in Toronto and presented a recent work. 

                    <table cellpadding=8px>
                        <tr>
                            <td valign=center align=center width=30%>
                                See press coverage of both schools by <a href="https://www.forbes.com/sites/williamfalcon/2018/09/03/an-insiders-look-into-the-summer-school-training-the-worlds-top-ai-researchers/#1d429741a05f">Forbes</a>.        
                            </td>
                            <td valign=center align="left" width=70%>
                                <img src="./images/RLSS-class.jpg" height="280" border=1/>
                            </td>
                        </tr>
                    </table>
                </li>

            	<!--li>
                    <b>Feb 2018:</b> I gave a talk at the <a href="https://aaai.org/Conferences/AAAI-18/">32nd AAAI Conf. on Artificial Intelligence</a> (<b>AAAI 2018</b>):
                    [<a href="https://youtu.be/u0dCuln_a-Q">video</a> | <a href="talks/AAAI-2018-slides.pdf">slides</a>]<br>
                    
                </li><br-->

                <!--li>
                    <b>Nov 2017:</b> Two papers accepted for presentation at the <a href="https://sites.google.com/view/deeprl-symposium-nips2017/">Deep Reinforcement Learning Symposium</a>, <a href="https://nips.cc/Conferences/2017/">31st Conf. on Neural Information Processing Systems</a> (<b>NIPS 2017</b>), Los Angeles, California:<br>
                        &rarr; <b>Action Branching Architectures for Deep Reinforcement Learning</b> [<a href="posters/NIPS-2017-DRLS-poster-1.pdf">poster</a> | <a href="https://arxiv.org/abs/1711.08946">arXiv</a> | <a href="https://github.com/atavakol/action-branching-agents">code</a>]<br>

                        &rarr; <b>Time Limits in Reinforcement Learning</b> [<a href="posters/NIPS-2017-DRLS-poster-2.pdf">poster</a> | <a href="https://arxiv.org/abs/1712.00378">arXiv</a> | <a href="https://sites.google.com/view/time-limits-in-rl">videos</a>]   
                </li><br-->

                <li class="bottom-three">
                    Dec 2017: Presented two papers at the <a href="https://sites.google.com/view/deeprl-symposium-nips2017/">Deep Reinforcement Learning Symposium</a>, <a href="https://nips.cc/Conferences/2017/">Conference on Neural Information Processing Systems (NIPS)</a> 2017 in Los Angeles, California.<br>
                        <!-- &rarr; <b>Action Branching Architectures for Deep Reinforcement Learning</b> [<a href="posters/NIPS-2017-DRLS-poster-1.pdf">poster</a> | <a href="https://arxiv.org/abs/1711.08946">arXiv</a> | <a href="https://github.com/atavakol/action-branching-agents">code</a>]<br>

                        &rarr; <b>Time Limits in Reinforcement Learning</b> [<a href="posters/NIPS-2017-DRLS-poster-2.pdf">poster</a> | <a href="https://arxiv.org/abs/1712.00378">arXiv</a> | <a href="https://sites.google.com/view/time-limits-in-rl">videos</a>]   
                </li><br-->
                </li>

                <!--li>
                    <b>Nov 2017:</b> Paper accepted for publication at the <a href="https://aaai.org/Conferences/AAAI-18/">32nd AAAI Conf. on Artificial Intelligence</a> (<b>AAAI 2018</b>):<br> 
                        &rarr; <b>Action Branching Architectures for Deep Reinforcement Learning</b> [<a href="papers/AAAI-2018.pdf">PDF</a> | <a href="https://arxiv.org/abs/1711.08946">arXiv</a> | <a href="https://github.com/atavakol/action-branching-agents">code</a>]
                </li><br-->
                
                <li class="bottom-three">
                    Sep 2017: Attended the <a href="http://www.deeplearningindaba.com/2017.html">Deep Learning Indaba Summer School</a>, co-organized by <a href="https://deepmind.com/">DeepMind</a>, in Johannesburg, South Africa.
                </li>

                <li class="bottom-three">
                    Aug 2017: Passed my first official PhD milestone with <a href="https://www.imperial.ac.uk/people/a.gyorgy">András György</a> as my examiner.
                </li>
            </ul>
        </div>
    </div>

    <div class="row">
        <div class="col-md-4 col-md-offset-4">
            <h2>Education</h2>
            <ul>
                <li>
                    2016 – Present:<br><ul>
                        <li><a href="https://www.imperial.ac.uk/"><b>Imperial College London</b></a>, London, United Kingdom</li>
                        <li>PhD Candidate in Computer Science</li> 
                        <li>Focus: Deep Reinforcement Learning</li>
                </ul></li>

                <li>
                    2014 – 2016:<br><ul>
                        <li><a href="https://www.usc.edu/"><b>University of Southern California</b></a>, Los Angeles, California</li>
                        <li>MSc in Computer Science</li>
                        <li>Focus: Multi-Agent Coordination</li>
                </ul></li>

                <li>
                    2010 – 2014:<br><ul>
                        <li><a href="https://www.ucl.ac.uk/"><b>University College London</b></a>, London, United Kingdom</li>
                        <li>MEng in Electrical Engineering (<i>First-Class Honours</i>)</li>
                        <li><font color="green"><strong>Remark: </strong></font> <i>Dean's List Recognition</i></li>
                </ul></li>

                <li>
                    2012 – 2013:<br><ul>
                        <li><a href="https://www.gatech.edu/"><b>Georgia Institute of Technology</b></a>, Atlanta, Georgia</li>
                        <li>Visiting Student in Electrical and Computer Engineering</li>
                        <li>Focus: Multi-Agent Coordination</li>
                </ul></li>
            </ul>
        </div>
    </div>

    <div class="row">
        <div class="col-md-4 col-md-offset-4">
            <h2>Publications</h2>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
                <tr onmouseout="uml_stop()" onmouseover="uml_start()">
                    <td width="20%">
                        <!--heading2><i>Recent Preprints</i></heading2><br><br-->
                        <div class="one" align="center">
                            <img src="./images/pss-frontpage.png" height=90 >
                        </div>
                    </td>
                    <td valign="top" width="80%">
                        <!--heading2><i></i></heading2><br-->
                        <p>
                        <b>Prioritizing Starting States for Reinforcement Learning</b><br>
                        <b>Arash Tavakoli</b>*, Vitaly Levdik*, Riashat Islam, Petar Kormushev<br>
                        In <i>Workshop on Deep Reinforcement Learning, Conference on Neural Information Processing Systems (NeurIPS)</i>, 2018.<br> 
                        [<a href="https://arxiv.org/abs/1811.11298">arXiv</a>]
                        </p><p></p>
                        <!--p> Abstract
                        </p-->
                    </td>
                </tr>

                <tr onmouseout="uml_stop()" onmouseover="uml_start()">
                    <td width="20%">
                        <!--heading2><i>Recent Preprints</i></heading2><br><br-->
                        <div class="one" align="center">
                            <img src="./images/Hopper.png" height=170 >
                        </div>
                    </td>
                    <td valign="top" width="80%">
                        <!--heading2><i></i></heading2><br-->
                        <p>
                        <b>Time Limits in Reinforcement Learning</b><br>
                        Fabio Pardo, <b>Arash Tavakoli</b>, Vitaly Levdik, Petar Kormushev<br>
                        In <i>International Conference on Machine Learning (ICML)</i>, 2018.<br> 
                        [<a href="http://proceedings.mlr.press/v80/pardo18a.html">PMLR Library</a> | <a href="https://arxiv.org/abs/1712.00378">arXiv</a> | <a href="https://sites.google.com/view/time-limits-in-rl">website</a> | <a href="https://www.youtube.com/watch?v=UUqidOSMKLE&t=126s">talk<a>]
                        </p><p></p>
                        <!--p> Abstract
                        </p-->
                    </td>
                </tr>

                <tr onmouseout="uml_stop()" onmouseover="uml_start()">
                    <td width="20%">
                        <!--heading2><i>Recent Preprints</i></heading2><br><br-->
                        <div class="one" align="center">
                            <img src="./images/action-branching.png" height=90 >
                        </div>
                    </td>
                    <td valign="top" width="80%">
                        <!--heading2><i></i></heading2><br-->
                        <p>
                        <b>Action Branching Architectures for Deep Reinforcement Learning</b><br>
                        <b>Arash Tavakoli</b>, Fabio Pardo, Petar Kormushev. <br>
                        In <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2018. <br>
                        <font color="green"><b>Press: </b></font>[<a href="https://blogs.unity3d.com/2018/09/11/ml-agents-toolkit-v0-5-new-resources-for-ai-researchers-available-now/">Unity ML-Agents blog ("Additional new features")</a>] <br>
                        [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17222">AAAI Library</a> | <a href="https://arxiv.org/abs/1711.08946">arXiv</a> | <a href="https://github.com/atavakol/action-branching-agents">code</a> | <a href="https://youtu.be/u0dCuln_a-Q"><font color="green"><strong>Long Talk</strong></font></a>]
                        </p><p></p>
                        <!--p> Abstract
                        </p-->
                    </td>
                </tr>

                <tr onmouseout="uml_stop()" onmouseover="uml_start()">
                    <td width="20%">
                        <!--heading2><i>Recent Preprints</i></heading2><br><br-->
                        <div class="one" align="center">
                            <img src="./images/crowdsourced-coordination-faded-path.png" width=200 >
                        </div>
                    </td>
                    <td valign="top" width="80%">
                        <!--heading2><i></i></heading2><br-->
                        <p>
                        <b>Crowdsourced Coordination through Online Games</b><br>
                        <b>Arash Tavakoli</b>, Haig Nalbandian, Nora Ayanian. <br>
                        In <i>ACM/IEEE International Conference on Human-Robot Interaction (HRI)</i>, 2016.<br> 
                        <font color="green"><b>Press: </b></font>[<a href="https://www.youtube.com/watch?v=pPHwwt9dl8w">MIT Technology Review (0:34s)</a>] <br>
                        [<a href="https://dl.acm.org/citation.cfm?id=2906960">ACM Library</a> | <a href="https://ieeexplore.ieee.org/document/7451839">IEEE Xplore Library</a> | <a href="papers/HRI-2016.pdf">preprint</a>] <br>
                        See also: [<a href="papers/ICRA-2016-Workshop.pdf">ICRA workshop version</a> | <a href="papers/Technical-Report-2016.pdf">game design report</a>]
                        </p><p></p>
                        <!--p> Abstract
                        </p-->
                    </td>
                </tr>

                <tr onmouseout="uml_stop()" onmouseover="uml_start()">
                    <td width="20%">
                        <!--heading2><i>Recent Preprints</i></heading2><br><br-->
                        <div class="one" align="center">
                            <img src="./images/robot-sim-intergration.png" width=200 >
                        </div>
                    </td>
                    <td valign="top" width="80%">
                        <!--heading2><i></i></heading2><br-->
                        <p>
                        <b>Seamless Robot Simulation Integration for Education: A Case Study</b><br>
                        Wolfgang Hönig, <b>Arash Tavakoli</b>, Nora Ayanian. <br>
                        In <i>Workshop on Simulation in Robot Programming, IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)</i>, 2016.<br> 
                        [<a href="papers/SIMPAR-2016-Workshop.pdf">PDF</a> | <a href="https://pycreate2.readthedocs.io/en/latest/index.html">website</a> | <a href="https://github.com/USC-ACTLab/pyCreate2">code</a>]
                        </p><p></p>
                        <!--p> Abstract
                        </p-->
                    </td>
                </tr>

            </table>

        </div>
    </div>


    <!-- /.container -->

    <!-- jQuery -->
    <!--script src="js/jquery.js"></script-->

    <!-- Bootstrap Core JavaScript -->
    <!--script src="js/bootstrap.min.js"></script-->

</body>

</html>
